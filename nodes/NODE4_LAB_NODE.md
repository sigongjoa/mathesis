# Node 4: Lab Node - í•™ìƒ ê´€ë¦¬ ë° í•™ìŠµ ë°ì´í„° ì¶”ì  ì—”ì§„

> í•™ìƒì˜ í•™ìŠµ í™œë™ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ê³ , ê°œë…ë³„ íˆíŠ¸ë§µì„ ìƒì„±í•˜ë©°, ì‹¤íŒ¨ íŒ¨í„´ì„ ë¶„ì„í•˜ëŠ” êµìœ¡ ë°ì´í„° í”Œë«í¼

**ì‘ì„±ì¼**: 2026-01-08
**ë²„ì „**: 1.0
**ìƒíƒœ**: Design Phase
**Port**: 8004 (FastAPI), stdio (MCP)

---

## ğŸ“‹ ëª©ì°¨

1. [ê°œìš”](#1-ê°œìš”)
2. [ì•„í‚¤í…ì²˜](#2-ì•„í‚¤í…ì²˜)
3. [MCP Tools ëª…ì„¸](#3-mcp-tools-ëª…ì„¸)
4. [íˆíŠ¸ë§µ ì‹œê°í™”](#4-íˆíŠ¸ë§µ-ì‹œê°í™”)
5. [ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨](#5-ì‹œí€€ìŠ¤-ë‹¤ì´ì–´ê·¸ë¨)
6. [í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨](#6-í´ë˜ìŠ¤-ë‹¤ì´ì–´ê·¸ë¨)
7. [êµ¬í˜„ ê°€ì´ë“œ](#7-êµ¬í˜„-ê°€ì´ë“œ)

---

## 1. ê°œìš”

### 1.1 ëª©ì 

**Lab Node**ëŠ” Mathesis-Synapseì˜ "ê´€ì œ ì„¼í„°"ì…ë‹ˆë‹¤. ëª¨ë“  í•™ìƒì˜ í•™ìŠµ í™œë™ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê¸°ë¡í•˜ê³ , ê°œë…ë³„ ìˆ™ë ¨ë„ë¥¼ **íˆíŠ¸ë§µ**ìœ¼ë¡œ ì‹œê°í™”í•˜ë©°, ë°˜ë³µë˜ëŠ” **ì‹¤íŒ¨ íŒ¨í„´**ì„ ê°ì§€í•˜ì—¬ Orchestratorê°€ ì ì ˆí•œ ê°œì…ì„ í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•©ë‹ˆë‹¤.

**í•µì‹¬ ê°€ì¹˜**:
- ğŸ“Š **í•™ìŠµ íˆíŠ¸ë§µ**: ê°œë…ë³„ ìˆ™ë ¨ë„ë¥¼ ìƒ‰ìƒìœ¼ë¡œ í‘œí˜„ (ë¹¨ê°•=ì•½í•¨, ì´ˆë¡=ê°•í•¨)
- ğŸ” **ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„**: "í•¨ìˆ˜ ë¬¸ì œë¥¼ ë°˜ë³µì ìœ¼ë¡œ í‹€ë¦¼" ê°™ì€ íŒ¨í„´ ê°ì§€
- ğŸ“ **í™œë™ ë¡œê·¸**: ëª¨ë“  í•™ìŠµ í™œë™ ê¸°ë¡ (ë¬¸ì œ í’€ì´, ì˜ìƒ ì‹œì²­, ê°œë… ë³µìŠµ)
- ğŸ¯ **ê°œì… íŠ¸ë¦¬ê±°**: íŠ¹ì • ì¡°ê±´ ì¶©ì¡± ì‹œ Orchestratorì— ì´ë²¤íŠ¸ ë°œìƒ

### 1.2 ì£¼ìš” ê¸°ëŠ¥

| ê¸°ëŠ¥ | ì„¤ëª… | MCP Tool |
|------|------|----------|
| **íˆíŠ¸ë§µ ì—…ë°ì´íŠ¸** | í•™ìƒì˜ ê°œë…ë³„ ìˆ™ë ¨ë„ ê°±ì‹  (BKT ì—°ë™) | `update_student_heatmap` |
| **í™œë™ ë¡œê¹…** | ëª¨ë“  í•™ìŠµ í™œë™ ê¸°ë¡ | `log_activity` |
| **ì‹¤íŒ¨ íŒ¨í„´ ì¡°íšŒ** | í•™ìƒì˜ ìµœê·¼ ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ | `get_failure_pattern` |

### 1.3 ê¸°ìˆ  ìŠ¤íƒ

| ê³„ì¸µ | ê¸°ìˆ  | ìš©ë„ |
|------|------|------|
| **MCP Server** | `mcp` Python SDK | LLMê³¼ì˜ Tool í†µì‹  |
| **Database** | PostgreSQL 14+ | í•™ìƒ ë°ì´í„°, í™œë™ ë¡œê·¸, íˆíŠ¸ë§µ |
| **Visualization** | Plotly, Seaborn | íˆíŠ¸ë§µ ì´ë¯¸ì§€ ìƒì„± |
| **Caching** | Redis | ì‹¤ì‹œê°„ í™œë™ ë°ì´í„° ìºì‹± |

---

## 2. ì•„í‚¤í…ì²˜

### 2.1 ì‹œìŠ¤í…œ êµ¬ì¡°

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  LLM Orchestrator                        â”‚
â”‚         "í•™ìƒì˜ ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ìš”ì²­"                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚ MCP Protocol
                        â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚    Lab Node MCP Server      â”‚
         â”‚                             â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
         â”‚  â”‚ update_heatmap      â”‚   â”‚
         â”‚  â”‚ log_activity        â”‚   â”‚
         â”‚  â”‚ get_failure_pattern â”‚   â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
         â”‚                             â”‚
         â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
         â”‚  â”‚ Core Logic Layer    â”‚   â”‚
         â”‚  â”‚ - Heatmap Manager   â”‚   â”‚
         â”‚  â”‚ - Activity Logger   â”‚   â”‚
         â”‚  â”‚ - Pattern Detector  â”‚   â”‚
         â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚   PostgreSQL    â”‚
       â”‚  - students     â”‚
       â”‚  - heatmap      â”‚
       â”‚  - activity_log â”‚
       â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚
       â”Œâ”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”
       â”‚   Redis   â”‚
       â”‚  (Cache)  â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 íˆíŠ¸ë§µ ì—…ë°ì´íŠ¸ í”Œë¡œìš°

```
1. í•™ìƒì´ ë¬¸ì œ í’€ì´ ì™„ë£Œ
   â†“
2. Q-DNA: BKTë¡œ ìˆ™ë ¨ë„ ê³„ì‚° â†’ P(ë„í•¨ìˆ˜) = 0.75
   â†“
3. Orchestrator: Lab-Node.update_student_heatmap()
   â†“
4. Lab Node:
   - PostgreSQLì— ìƒˆ ìˆ™ë ¨ë„ ì €ì¥
   - Redis ìºì‹œ ê°±ì‹ 
   - íˆíŠ¸ë§µ ì´ë¯¸ì§€ ì¬ìƒì„± (Plotly)
   â†“
5. Return: {old_mastery: 0.65, new_mastery: 0.75}
```

---

## 3. MCP Tools ëª…ì„¸

### 3.1 Tool: `update_student_heatmap`

**ëª©ì **: í•™ìƒì˜ ê°œë…ë³„ ìˆ™ë ¨ë„ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  íˆíŠ¸ë§µ ì¬ìƒì„±

**Input Schema**:
```python
class UpdateStudentHeatmapInput(BaseModel):
    student_id: str
    concept_id: str
    attempt_result: bool = Field(
        description="ì •ë‹µ ì—¬ë¶€"
    )
    mastery_level: Optional[float] = Field(
        default=None,
        description="ëª…ì‹œì  ìˆ™ë ¨ë„ (BKT ê²°ê³¼). Noneì´ë©´ ìë™ ê³„ì‚°"
    )
    confidence: float = Field(
        default=0.8,
        description="ìˆ™ë ¨ë„ ì˜ˆì¸¡ ì‹ ë¢°ë„"
    )
```

**Output Schema**:
```python
class UpdateStudentHeatmapOutput(BaseModel):
    student_id: str
    concept_id: str
    old_mastery: float
    new_mastery: float
    mastery_change: float  # new - old
    confidence: float
    updated_at: str  # ISO datetime
```

**êµ¬í˜„**:
```python
async def update_student_heatmap(input: UpdateStudentHeatmapInput):
    # 1. í˜„ì¬ ìˆ™ë ¨ë„ ì¡°íšŒ
    current = await db.get_student_mastery(
        input.student_id,
        input.concept_id
    )
    old_mastery = current.get("mastery_level", 0.0) if current else 0.0

    # 2. ìƒˆ ìˆ™ë ¨ë„ ê³„ì‚° (ëª…ì‹œì  ê°’ ë˜ëŠ” ìë™ ê³„ì‚°)
    if input.mastery_level is not None:
        new_mastery = input.mastery_level
    else:
        # BKT ê°„ë‹¨ ë²„ì „ (ì‹¤ì œëŠ” Q-DNAì—ì„œ ê³„ì‚°)
        if input.attempt_result:
            new_mastery = old_mastery + (1 - old_mastery) * 0.3
        else:
            new_mastery = old_mastery * 0.8

    # 3. DB ì €ì¥
    await db.upsert_student_mastery({
        "student_id": input.student_id,
        "concept_id": input.concept_id,
        "mastery_level": new_mastery,
        "attempts_count": current.get("attempts_count", 0) + 1 if current else 1,
        "last_updated": datetime.now()
    })

    # 4. Redis ìºì‹œ ê°±ì‹ 
    await redis.hset(
        f"heatmap:{input.student_id}",
        input.concept_id,
        new_mastery
    )

    return UpdateStudentHeatmapOutput(
        student_id=input.student_id,
        concept_id=input.concept_id,
        old_mastery=old_mastery,
        new_mastery=new_mastery,
        mastery_change=new_mastery - old_mastery,
        confidence=input.confidence,
        updated_at=datetime.now().isoformat()
    )
```

---

### 3.2 Tool: `log_activity`

**ëª©ì **: í•™ìƒì˜ ëª¨ë“  í•™ìŠµ í™œë™ì„ ì‹œê³„ì—´ë¡œ ê¸°ë¡

**Input Schema**:
```python
class LogActivityInput(BaseModel):
    student_id: str
    activity_type: str = Field(
        description="í™œë™ ìœ í˜•",
        example="question_attempt"
    )
    metadata: dict = Field(
        description="í™œë™ ë©”íƒ€ë°ì´í„° (JSONB)",
        example={
            "question_id": 42,
            "is_correct": True,
            "time_spent": 120
        }
    )
    session_id: Optional[str] = Field(
        default=None,
        description="ì„¸ì…˜ ID (ì—°ì† í™œë™ ê·¸ë£¹í™”)"
    )
```

**Output Schema**:
```python
class LogActivityOutput(BaseModel):
    activity_id: int
    student_id: str
    activity_type: str
    logged_at: str  # ISO datetime
```

**í™œë™ ìœ í˜•**:
```python
ACTIVITY_TYPES = {
    "question_attempt": "ë¬¸ì œ í’€ì´ ì‹œë„",
    "video_watch": "ê°œë… ì˜ìƒ ì‹œì²­",
    "concept_review": "ê°œë… ë³µìŠµ",
    "hint_request": "íŒíŠ¸ ìš”ì²­",
    "explanation_view": "í•´ì„¤ ë³´ê¸°",
    "practice_set_start": "ì—°ìŠµ ì„¸íŠ¸ ì‹œì‘",
    "practice_set_complete": "ì—°ìŠµ ì„¸íŠ¸ ì™„ë£Œ"
}
```

**êµ¬í˜„**:
```python
async def log_activity(input: LogActivityInput):
    # 1. DB ì‚½ì…
    activity_id = await db.insert_activity_log({
        "student_id": input.student_id,
        "activity_type": input.activity_type,
        "metadata": input.metadata,
        "session_id": input.session_id,
        "created_at": datetime.now()
    })

    # 2. Redis ìŠ¤íŠ¸ë¦¼ (ì‹¤ì‹œê°„ ì´ë²¤íŠ¸)
    await redis.xadd(
        f"activity_stream:{input.student_id}",
        {
            "type": input.activity_type,
            "metadata": json.dumps(input.metadata)
        },
        maxlen=1000  # ìµœê·¼ 1000ê°œë§Œ ìœ ì§€
    )

    # 3. ì´ë²¤íŠ¸ íŠ¸ë¦¬ê±° (ì¡°ê±´ ì¶©ì¡± ì‹œ)
    await check_intervention_triggers(input.student_id, input.activity_type)

    return LogActivityOutput(
        activity_id=activity_id,
        student_id=input.student_id,
        activity_type=input.activity_type,
        logged_at=datetime.now().isoformat()
    )
```

---

### 3.3 Tool: `get_failure_pattern`

**ëª©ì **: í•™ìƒì˜ ìµœê·¼ ì‹¤íŒ¨ íŒ¨í„´ì„ ë¶„ì„í•˜ì—¬ ì•½ì  ì‹ë³„

**Input Schema**:
```python
class GetFailurePatternInput(BaseModel):
    student_id: str
    time_range: str = Field(
        default="last_7_days",
        description="ë¶„ì„ ê¸°ê°„ (last_7_days, last_30_days, all)"
    )
    min_difficulty: float = Field(
        default=0.0,
        description="ìµœì†Œ ë‚œì´ë„ (ì‰¬ìš´ ë¬¸ì œ ì œì™¸)"
    )
    group_by: str = Field(
        default="concept",
        description="ê·¸ë£¹í™” ê¸°ì¤€ (concept, dna_type, cognitive_level)"
    )
```

**Output Schema**:
```python
class FailurePattern(BaseModel):
    group_key: str  # ê°œë… ID ë˜ëŠ” DNA íƒ€ì…
    total_attempts: int
    failed_attempts: int
    failure_rate: float
    avg_difficulty: float
    recent_trend: str  # "worsening", "stable", "improving"

class GetFailurePatternOutput(BaseModel):
    student_id: str
    analysis_period: str
    total_attempts: int
    total_failures: int
    overall_failure_rate: float
    patterns: List[FailurePattern]
    weak_concepts: List[str]
    recommended_action: str  # "review", "easier_problems", "concept_video"
```

**êµ¬í˜„**:
```python
async def get_failure_pattern(input: GetFailurePatternInput):
    # 1. ê¸°ê°„ íŒŒì‹±
    time_filter = parse_time_range(input.time_range)

    # 2. PostgreSQL ì¿¼ë¦¬
    query = """
    SELECT
        q.{group_by} AS group_key,
        COUNT(*) AS total_attempts,
        SUM(CASE WHEN NOT a.is_correct THEN 1 ELSE 0 END) AS failed_attempts,
        AVG(q.difficulty) AS avg_difficulty
    FROM attempts a
    JOIN questions q ON a.question_id = q.id
    WHERE a.student_id = $1
      AND a.created_at >= $2
      AND q.difficulty >= $3
    GROUP BY q.{group_by}
    HAVING SUM(CASE WHEN NOT a.is_correct THEN 1 ELSE 0 END) > 0
    ORDER BY failed_attempts DESC
    """.format(group_by=input.group_by)

    results = await db.query(query, input.student_id, time_filter, input.min_difficulty)

    # 3. íŒ¨í„´ ë¶„ì„
    patterns = []
    for row in results:
        failure_rate = row["failed_attempts"] / row["total_attempts"]

        # íŠ¸ë Œë“œ ë¶„ì„ (ìµœê·¼ 5ê°œ vs ì´ì „ 5ê°œ)
        trend = await analyze_trend(input.student_id, row["group_key"])

        patterns.append(FailurePattern(
            group_key=row["group_key"],
            total_attempts=row["total_attempts"],
            failed_attempts=row["failed_attempts"],
            failure_rate=failure_rate,
            avg_difficulty=row["avg_difficulty"],
            recent_trend=trend
        ))

    # 4. ì•½ì  ê°œë… ì¶”ì¶œ (ì‹¤íŒ¨ìœ¨ > 50%)
    weak_concepts = [p.group_key for p in patterns if p.failure_rate > 0.5]

    # 5. ì¶”ì²œ ì•¡ì…˜ ê²°ì •
    if len(weak_concepts) > 3:
        recommended_action = "review"  # ê¸°ì´ˆ ê°œë… ë³µìŠµ
    elif max((p.avg_difficulty for p in patterns), default=0) > 0.8:
        recommended_action = "easier_problems"  # ì‰¬ìš´ ë¬¸ì œë¶€í„°
    else:
        recommended_action = "concept_video"  # ê°œë… ì˜ìƒ

    return GetFailurePatternOutput(
        student_id=input.student_id,
        analysis_period=input.time_range,
        total_attempts=sum(p.total_attempts for p in patterns),
        total_failures=sum(p.failed_attempts for p in patterns),
        overall_failure_rate=sum(p.failed_attempts for p in patterns) / sum(p.total_attempts for p in patterns),
        patterns=patterns,
        weak_concepts=weak_concepts,
        recommended_action=recommended_action
    )
```

---

## 4. íˆíŠ¸ë§µ ì‹œê°í™”

### 4.1 íˆíŠ¸ë§µ ìƒì„± (Plotly)

```python
import plotly.graph_objects as go

async def generate_heatmap_image(student_id: str) -> str:
    # 1. í•™ìƒì˜ ëª¨ë“  ê°œë… ìˆ™ë ¨ë„ ì¡°íšŒ
    mastery_data = await db.get_student_heatmap(student_id)

    # 2. êµìœ¡ê³¼ì • íŠ¸ë¦¬ êµ¬ì¡°ë¡œ ë³€í™˜
    tree = build_curriculum_tree(mastery_data)
    # ì˜ˆ: {"ë¯¸ì ë¶„": {"ë„í•¨ìˆ˜": 0.75, "ì ë¶„": 0.45}, "ëŒ€ìˆ˜": {...}}

    # 3. Plotly Heatmap
    concepts = list(tree.keys())
    subconcepts = []
    values = []

    for concept, subs in tree.items():
        subconcepts.extend(subs.keys())
        values.extend(subs.values())

    fig = go.Figure(data=go.Heatmap(
        z=[values],
        x=subconcepts,
        y=concepts,
        colorscale=[
            [0, 'red'],      # 0.0: ë¹¨ê°• (ì•½í•¨)
            [0.5, 'yellow'], # 0.5: ë…¸ë‘ (ì¤‘ê°„)
            [1, 'green']     # 1.0: ì´ˆë¡ (ê°•í•¨)
        ],
        colorbar=dict(title="ìˆ™ë ¨ë„")
    ))

    fig.update_layout(
        title=f"í•™ìŠµ íˆíŠ¸ë§µ: {student_id}",
        xaxis_title="ì„¸ë¶€ ê°œë…",
        yaxis_title="ëŒ€ë¶„ë¥˜"
    )

    # 4. ì´ë¯¸ì§€ ì €ì¥
    output_path = f"/tmp/heatmap_{student_id}.png"
    fig.write_image(output_path)

    return output_path
```

---

## 5. ì‹œí€€ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨

### 5.1 ì‹¤íŒ¨ íŒ¨í„´ ì¡°íšŒ í”Œë¡œìš°

```plantuml
@startuml
title Lab Node: get_failure_pattern ì‹œí€€ìŠ¤

actor Orchestrator
participant "Lab MCP" as MCP
participant "Pattern\nDetector" as Detector
database PostgreSQL
database Redis

Orchestrator -> MCP: get_failure_pattern(\n  student_id="student_123",\n  time_range="last_7_days"\n)
activate MCP

MCP -> Detector: 1. ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„ ìš”ì²­
activate Detector

Detector -> PostgreSQL: 2. ìµœê·¼ 7ì¼ ì‘ë‹µ ì´ë ¥ ì¡°íšŒ
activate PostgreSQL
note right
SELECT concept, COUNT(*), SUM(is_correct)
FROM attempts
WHERE student_id = 'student_123'
  AND created_at >= NOW() - INTERVAL '7 days'
GROUP BY concept
HAVING SUM(is_correct) < COUNT(*) / 2
end note
PostgreSQL --> Detector: ì‹¤íŒ¨ê°€ ë§ì€ ê°œë… ëª©ë¡
deactivate PostgreSQL

Detector -> Detector: 3. íŠ¸ë Œë“œ ë¶„ì„\n(ìµœê·¼ vs ì´ì „)
note right
ìµœê·¼ 5ê°œ ì‹œë„ ì‹¤íŒ¨ìœ¨
vs
ì´ì „ 5ê°œ ì‹œë„ ì‹¤íŒ¨ìœ¨
â†’ "worsening", "stable", "improving"
end note

Detector -> Redis: 4. ìºì‹œ ì €ì¥
activate Redis
note right
íŒ¨í„´ ë¶„ì„ ê²°ê³¼ëŠ” ìì£¼ ì¡°íšŒë˜ë¯€ë¡œ
Redisì— 1ì‹œê°„ ìºì‹±
end note
Redis --> Detector: cached
deactivate Redis

Detector --> MCP: GetFailurePatternOutput{\n  weak_concepts: ["ê·¹í•œ", "ë„í•¨ìˆ˜"],\n  recommended_action: "concept_video"\n}
deactivate Detector

MCP --> Orchestrator: ì‹¤íŒ¨ íŒ¨í„´ ê²°ê³¼
deactivate MCP

@enduml
```

---

## 6. í´ë˜ìŠ¤ ë‹¤ì´ì–´ê·¸ë¨

```plantuml
@startuml
title Lab Node Class Diagram

package "MCP Server Layer" {
  class LabNodeMCPServer {
    +update_student_heatmap(input): UpdateStudentHeatmapOutput
    +log_activity(input): LogActivityOutput
    +get_failure_pattern(input): GetFailurePatternOutput
  }
}

package "Core Logic Layer" {
  class HeatmapManager {
    -db: PostgreSQLRepository
    -redis: RedisClient
    +update_mastery(student, concept, mastery): void
    +get_heatmap_data(student): dict
    +generate_heatmap_image(student): str
  }

  class ActivityLogger {
    -db: PostgreSQLRepository
    -redis: RedisClient
    +log(student, type, metadata): int
    +get_recent_activities(student, limit): List[Activity]
    +check_triggers(student, activity): void
  }

  class PatternDetector {
    -db: PostgreSQLRepository
    +analyze_failures(student, time_range): List[FailurePattern]
    +calculate_trend(student, concept): str
    +recommend_action(patterns): str
  }

  class HeatmapVisualizer {
    +generate_plotly_heatmap(data): str
    +build_curriculum_tree(mastery_data): dict
  }
}

package "Data Layer" {
  class PostgreSQLRepository {
    -engine: SQLAlchemy.Engine
    +get_student_mastery(student, concept): dict
    +upsert_student_mastery(data): void
    +insert_activity_log(data): int
    +query_failure_patterns(student, filters): List[dict]
  }

  class RedisClient {
    +hset(key, field, value): void
    +hget(key, field): str
    +xadd(stream, data): void
    +xread(stream, count): List[dict]
  }
}

LabNodeMCPServer --> HeatmapManager: uses
LabNodeMCPServer --> ActivityLogger: uses
LabNodeMCPServer --> PatternDetector: uses

HeatmapManager --> PostgreSQLRepository: uses
HeatmapManager --> RedisClient: uses
HeatmapManager --> HeatmapVisualizer: uses
ActivityLogger --> PostgreSQLRepository: uses
ActivityLogger --> RedisClient: uses
PatternDetector --> PostgreSQLRepository: uses

@enduml
```

---

## 7. êµ¬í˜„ ê°€ì´ë“œ

### 7.1 í”„ë¡œì íŠ¸ êµ¬ì¡°

```
node4_lab_node/
â”œâ”€â”€ mcp_server.py
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ heatmap_manager.py
â”‚   â”œâ”€â”€ activity_logger.py
â”‚   â”œâ”€â”€ pattern_detector.py
â”‚   â””â”€â”€ heatmap_visualizer.py
â”œâ”€â”€ repositories/
â”‚   â”œâ”€â”€ postgres_repo.py
â”‚   â””â”€â”€ redis_client.py
â”œâ”€â”€ models/
â”‚   â””â”€â”€ schemas.py
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ update_student_heatmap.py
â”‚   â”œâ”€â”€ log_activity.py
â”‚   â””â”€â”€ get_failure_pattern.py
â””â”€â”€ tests/
    â”œâ”€â”€ test_heatmap.py
    â””â”€â”€ test_pattern_detection.py
```

### 7.2 Redis ìŠ¤íŠ¸ë¦¼ í™œìš©

```python
# core/activity_logger.py
import redis.asyncio as redis

class ActivityLogger:
    def __init__(self):
        self.redis = redis.Redis(host='localhost', port=6379)

    async def log_to_stream(self, student_id: str, activity: dict):
        """ì‹¤ì‹œê°„ í™œë™ ìŠ¤íŠ¸ë¦¼"""
        stream_key = f"activity_stream:{student_id}"
        await self.redis.xadd(
            stream_key,
            activity,
            maxlen=1000  # ìµœê·¼ 1000ê°œë§Œ ìœ ì§€
        )

    async def get_recent_activities(self, student_id: str, count: int = 10):
        """ìµœê·¼ í™œë™ ì¡°íšŒ"""
        stream_key = f"activity_stream:{student_id}"
        entries = await self.redis.xrevrange(stream_key, count=count)
        return [entry[1] for entry in entries]
```

---

**ë‹¤ìŒ ë¬¸ì„œ**: [Node 5: Report Node Technical Overview](./NODE5_REPORT_NODE.md)
