# Node 0: Student Hub - Technical Design Document (TDD)

**Version**: 1.0.0
**Last Updated**: 2026-01-09
**Status**: Design Phase
**Author**: Mathesis Platform Team

---

## ğŸ“‹ Table of Contents

1. [ì‹œìŠ¤í…œ ê°œìš”](#1-ì‹œìŠ¤í…œ-ê°œìš”)
2. [ê¸°ìˆ  ìŠ¤íƒ](#2-ê¸°ìˆ -ìŠ¤íƒ)
3. [ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜](#3-ì‹œìŠ¤í…œ-ì•„í‚¤í…ì²˜)
4. [ì»´í¬ë„ŒíŠ¸ ì„¤ê³„](#4-ì»´í¬ë„ŒíŠ¸-ì„¤ê³„)
5. [ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„](#5-ë°ì´í„°ë² ì´ìŠ¤-ì„¤ê³„)
6. [MCP í†µì‹  ì„¤ê³„](#6-mcp-í†µì‹ -ì„¤ê³„)
7. [ì›Œí¬í”Œë¡œìš° ì—”ì§„](#7-ì›Œí¬í”Œë¡œìš°-ì—”ì§„)
8. [ì„±ëŠ¥ ìµœì í™”](#8-ì„±ëŠ¥-ìµœì í™”)
9. [ë³´ì•ˆ ì„¤ê³„](#9-ë³´ì•ˆ-ì„¤ê³„)
10. [ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…](#10-ëª¨ë‹ˆí„°ë§-ë°-ë¡œê¹…)

---

## 1. ì‹œìŠ¤í…œ ê°œìš”

### 1.1 ëª©ì 
Node 0 (Student Hub)ëŠ” Mathesis Platformì˜ **ë§ˆìŠ¤í„° ë…¸ë“œ**ë¡œì„œ ë‹¤ìŒ ì—­í• ì„ ìˆ˜í–‰:
- **Single Source of Truth**: ëª¨ë“  í•™ìƒ ë°ì´í„°ì˜ ë‹¨ì¼ ì§„ì‹¤ ê³µê¸‰ì›
- **Data Aggregator**: Node 1-6ì˜ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ 360ë„ í•™ìƒ í”„ë¡œí•„ ì œê³µ
- **Workflow Orchestrator**: êµìœ¡ ì›Œí¬í”Œë¡œìš° ìë™í™” ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜

### 1.2 í•µì‹¬ íŠ¹ì§•
- **ì´ì¤‘ ì—­í• **: MCP Server (ì™¸ë¶€ ì œê³µ) + MCP Client (ë‚´ë¶€ í˜¸ì¶œ)
- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: Redis ê¸°ë°˜ ìºì‹± ë° ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”
- **ë¹„ë™ê¸° ì²˜ë¦¬**: Celery ê¸°ë°˜ ë°±ê·¸ë¼ìš´ë“œ ì‘ì—… ì²˜ë¦¬
- **í™•ì¥ì„±**: ìˆ˜í‰ í™•ì¥ ê°€ëŠ¥í•œ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì„¤ê³„

### 1.3 ì œì•½ì‚¬í•­
| êµ¬ë¶„ | ì œì•½ì‚¬í•­ | ê·¼ê±° |
|------|----------|------|
| **ì‘ë‹µ ì‹œê°„** | í†µí•© í”„ë¡œí•„ ì¡°íšŒ < 2ì´ˆ | PRD KPI |
| **ë™ì‹œ ì‚¬ìš©ì** | 1,000ëª… ë™ì‹œ ì ‘ì† | Phase 1 ëª©í‘œ |
| **ë°ì´í„° ì •í•©ì„±** | Node ê°„ ë°ì´í„° ë™ê¸°í™” < 5ì´ˆ | UX ìš”êµ¬ì‚¬í•­ |
| **ê°€ìš©ì„±** | 99.5% ì´ìƒ | êµìœ¡ ì„œë¹„ìŠ¤ íŠ¹ì„± |

---

## 2. ê¸°ìˆ  ìŠ¤íƒ

### 2.1 Backend Framework
```yaml
Framework: FastAPI 0.104+
  - Async/Await ì§€ì›
  - Pydantic ê¸°ë°˜ ë°ì´í„° ê²€ì¦
  - OpenAPI ìë™ ìƒì„±
  - ë†’ì€ ì„±ëŠ¥ (Starlette + Uvicorn)

Python Version: 3.11+
  - Type Hints ì™„ì „ ì§€ì›
  - Performance ê°œì„  (10-60% faster)
  - Better error messages
```

### 2.2 Database Stack
```yaml
Primary DB: PostgreSQL 14+
  - í•™ìƒ ë§ˆìŠ¤í„° ë°ì´í„°
  - í•™ìŠµ íˆìŠ¤í† ë¦¬ (ì‹œê³„ì—´ ë°ì´í„°)
  - JSONB í•„ë“œ (ìœ ì—°í•œ ë©”íƒ€ë°ì´í„°)
  - Partitioning (í•™ìŠµ ì´ë²¤íŠ¸ í…Œì´ë¸”)

Cache: Redis 7+
  - í†µí•© í”„ë¡œí•„ ìºì‹œ (TTL: 300s)
  - ì„¸ì…˜ ê´€ë¦¬
  - Rate Limiting
  - Pub/Sub (ì‹¤ì‹œê°„ ì•Œë¦¼)

Task Queue: Redis (Celery Backend)
  - ë¹„ë™ê¸° ì‘ì—… í
  - ê²°ê³¼ ì €ì¥ì†Œ
```

### 2.3 Message Queue & Task Processing
```yaml
Task Queue: Celery 5.3+
  - ë¹„ë™ê¸° ì‘ì—… ì²˜ë¦¬
  - ì£¼ê¸°ì  ì‘ì—… ìŠ¤ì¼€ì¤„ë§ (Celery Beat)
  - ì¬ì‹œë„ ë©”ì»¤ë‹ˆì¦˜
  - Task ìš°ì„ ìˆœìœ„ ê´€ë¦¬

Broker: Redis
  - ë©”ì‹œì§€ ë¸Œë¡œì»¤
  - ê²°ê³¼ ë°±ì—”ë“œ
```

### 2.4 MCP Communication
```yaml
MCP Protocol:
  - Server: 4ê°œ Tools ì œê³µ
  - Client: Node 1-6 í˜¸ì¶œ
  - Transport: HTTP/JSON-RPC
  - Timeout: 30ì´ˆ (ê¸°ë³¸), 300ì´ˆ (ë¦¬í¬íŠ¸ ìƒì„±)
```

### 2.5 Monitoring & Logging
```yaml
Logging:
  - structlog (êµ¬ì¡°í™” ë¡œê¹…)
  - JSON í˜•ì‹
  - ì¤‘ì•™ ì§‘ì¤‘ì‹ (í–¥í›„ ELK Stack)

Metrics:
  - Prometheus client
  - Custom metrics (í•™ìƒ í™œë™, API í˜¸ì¶œ)

Tracing:
  - OpenTelemetry (í–¥í›„ í†µí•©)
```

---

## 3. ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 3.1 High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Clients                          â”‚
â”‚          (LLM Orchestrator, Frontend, CLI Tools)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ MCP Protocol
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Node 0: Student Hub (Port 8000)             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ MCP Server   â”‚  â”‚ REST API     â”‚  â”‚ Admin API    â”‚     â”‚
â”‚  â”‚ (4 Tools)    â”‚  â”‚ (Internal)   â”‚  â”‚ (Management) â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚         â”‚                  â”‚                  â”‚              â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â”‚
â”‚                            â†“                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           Service Layer (Business Logic)             â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ ProfileService   â€¢ InterventionService             â”‚  â”‚
â”‚  â”‚ â€¢ WorkflowService  â€¢ AnalyticsService                â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                                     â”‚            â”‚
â”‚           â†“                                     â†“            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ MCP Client      â”‚                  â”‚ Cache Layer      â”‚ â”‚
â”‚  â”‚ (Call Node 1-6) â”‚                  â”‚ (Redis)          â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚           â”‚                                     â”‚            â”‚
â”‚           â†“                                     â†“            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚              Data Access Layer (DAL)                  â”‚  â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  â”‚
â”‚  â”‚ â€¢ StudentRepository    â€¢ LearningHistoryRepository   â”‚  â”‚
â”‚  â”‚ â€¢ InterventionRepository â€¢ TaskRepository            â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚           â”‚                                                  â”‚
â”‚           â†“                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚  PostgreSQL      â”‚         â”‚  Celery Worker   â”‚         â”‚
â”‚  â”‚  (Master Data)   â”‚         â”‚  (Background)    â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â†“ MCP Protocol
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Downstream Services (Node 1-6)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¤
â”‚ Node 1   â”‚ Node 2   â”‚ Node 3   â”‚ Node 4   â”‚ Node 5   â”‚Node 6â”‚
â”‚ Logic    â”‚ Q-DNA    â”‚ Gen      â”‚ Lab      â”‚ Report   â”‚Schoolâ”‚
â”‚ Engine   â”‚ ë¬¸ì œì€í–‰  â”‚ AIìƒì„±   â”‚ í•™ìŠµì¶”ì  â”‚ ë¦¬í¬íŠ¸   â”‚ ì •ë³´ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 Deployment Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      Docker Compose                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  student-hub-api (Port 8000)                         â”‚   â”‚
â”‚  â”‚  â€¢ FastAPI Application                               â”‚   â”‚
â”‚  â”‚  â€¢ Uvicorn Server (4 workers)                        â”‚   â”‚
â”‚  â”‚  â€¢ Health Check: /health                             â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  student-hub-worker                                  â”‚   â”‚
â”‚  â”‚  â€¢ Celery Worker (Concurrency: 4)                    â”‚   â”‚
â”‚  â”‚  â€¢ Queues: default, high_priority, low_priority      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  student-hub-beat                                    â”‚   â”‚
â”‚  â”‚  â€¢ Celery Beat Scheduler                             â”‚   â”‚
â”‚  â”‚  â€¢ Periodic Tasks (Daily reports, Weekly analytics)  â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  postgres (Port 5432)                                â”‚   â”‚
â”‚  â”‚  â€¢ PostgreSQL 14                                     â”‚   â”‚
â”‚  â”‚  â€¢ Volume: ./data/postgres                           â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚  redis (Port 6379)                                   â”‚   â”‚
â”‚  â”‚  â€¢ Redis 7                                           â”‚   â”‚
â”‚  â”‚  â€¢ Persistence: AOF enabled                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Network: mathesis-network (Bridge)
```

### 3.3 Data Flow

#### 3.3.1 í†µí•© í”„ë¡œí•„ ì¡°íšŒ Flow
```
Client (LLM Orchestrator)
  â”‚
  â”‚ 1. MCP: get_unified_profile(student_id)
  â†“
MCP Server (FastAPI Endpoint)
  â”‚
  â”‚ 2. Check Cache
  â†“
Redis Cache
  â”‚
  â”œâ”€ Cache Hit â†’ Return Cached Profile (< 100ms)
  â”‚
  â””â”€ Cache Miss
      â”‚
      â”‚ 3. Fetch Master Data
      â†“
    PostgreSQL (students table)
      â”‚
      â”‚ 4. Aggregate Data (Parallel)
      â†“
    MCP Client (Concurrent Calls)
      â”œâ”€â†’ Node 1: get_knowledge_state(student_id)
      â”œâ”€â†’ Node 2: get_mastery_level(student_id)
      â”œâ”€â†’ Node 4: get_recent_activities(student_id)
      â””â”€â†’ Node 5: get_latest_reports(student_id)
      â”‚
      â”‚ 5. Merge Results
      â†“
    ProfileService.merge()
      â”‚
      â”‚ 6. Cache Result (TTL: 300s)
      â†“
    Redis Cache
      â”‚
      â”‚ 7. Return Unified Profile
      â†“
    Client
```

**Performance Budget**:
- Cache Hit: < 100ms
- Cache Miss: < 2000ms (4ê°œ ë…¸ë“œ ë³‘ë ¬ í˜¸ì¶œ)
- Node í˜¸ì¶œ Timeout: 500ms/node

#### 3.3.2 í•™ìŠµ ê°œì… ìƒì„± Flow
```
Client
  â”‚
  â”‚ 1. MCP: create_learning_intervention(student_id, config)
  â†“
MCP Server
  â”‚
  â”‚ 2. Validate Student
  â†“
PostgreSQL
  â”‚
  â”‚ 3. Analyze Performance
  â†“
MCP Client â†’ Node 2: analyze_weak_areas(student_id)
  â”‚
  â”‚ 4. Generate Learning Path
  â†“
MCP Client â†’ Node 3: generate_problem_set(weak_areas)
  â”‚
  â”‚ 5. Create Intervention (DB)
  â†“
PostgreSQL (interventions table)
  â”‚
  â”‚ 6. Schedule Follow-up (Async)
  â†“
Celery Task Queue
  â”‚
  â”‚ 7. Return Intervention ID
  â†“
Client
  â”‚
  â”‚ (Background)
  â†“
Celery Worker
  â”œâ”€â†’ Send Notification
  â”œâ”€â†’ Update Analytics
  â””â”€â†’ Schedule Progress Check (7 days later)
```

---

## 4. ì»´í¬ë„ŒíŠ¸ ì„¤ê³„

### 4.1 Directory Structure

```
node0_student_hub/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPI ì•± ì§„ì…ì 
â”‚   â”œâ”€â”€ config.py                  # ì„¤ì • ê´€ë¦¬ (Pydantic Settings)
â”‚   â”‚
â”‚   â”œâ”€â”€ api/                       # API Layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ deps.py                # ì˜ì¡´ì„± ì£¼ì…
â”‚   â”‚   â”œâ”€â”€ mcp/                   # MCP Server Endpoints
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ server.py          # MCP ì„œë²„ ì„¤ì •
â”‚   â”‚   â”‚   â””â”€â”€ tools/             # MCP Tools êµ¬í˜„
â”‚   â”‚   â”‚       â”œâ”€â”€ profile.py     # get_unified_profile
â”‚   â”‚   â”‚       â”œâ”€â”€ intervention.py # create_learning_intervention
â”‚   â”‚   â”‚       â”œâ”€â”€ scheduler.py   # schedule_periodic_task
â”‚   â”‚   â”‚       â””â”€â”€ analytics.py   # get_class_analytics
â”‚   â”‚   â”‚
â”‚   â”‚   â””â”€â”€ rest/                  # REST API (Internal)
â”‚   â”‚       â”œâ”€â”€ students.py        # í•™ìƒ CRUD
â”‚   â”‚       â”œâ”€â”€ interventions.py   # ê°œì… ê´€ë¦¬
â”‚   â”‚       â””â”€â”€ health.py          # Health Check
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                  # Business Logic Layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ profile_service.py     # í”„ë¡œí•„ í†µí•©
â”‚   â”‚   â”œâ”€â”€ intervention_service.py # ê°œì… ë¡œì§
â”‚   â”‚   â”œâ”€â”€ workflow_service.py    # ì›Œí¬í”Œë¡œìš° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜
â”‚   â”‚   â”œâ”€â”€ analytics_service.py   # ë¶„ì„ ë¡œì§
â”‚   â”‚   â””â”€â”€ mcp_client.py          # MCP Client (Node 1-6 í˜¸ì¶œ)
â”‚   â”‚
â”‚   â”œâ”€â”€ models/                    # Domain Models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ student.py             # Student ì—”í‹°í‹°
â”‚   â”‚   â”œâ”€â”€ intervention.py        # Intervention ì—”í‹°í‹°
â”‚   â”‚   â”œâ”€â”€ learning_history.py    # LearningHistory ì—”í‹°í‹°
â”‚   â”‚   â””â”€â”€ task.py                # ScheduledTask ì—”í‹°í‹°
â”‚   â”‚
â”‚   â”œâ”€â”€ schemas/                   # Pydantic Schemas (DTO)
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ student.py             # StudentCreate, StudentResponse
â”‚   â”‚   â”œâ”€â”€ profile.py             # UnifiedProfile
â”‚   â”‚   â”œâ”€â”€ intervention.py        # InterventionConfig, InterventionResult
â”‚   â”‚   â””â”€â”€ analytics.py           # ClassAnalytics
â”‚   â”‚
â”‚   â”œâ”€â”€ repositories/              # Data Access Layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ student_repo.py
â”‚   â”‚   â”œâ”€â”€ intervention_repo.py
â”‚   â”‚   â”œâ”€â”€ learning_history_repo.py
â”‚   â”‚   â””â”€â”€ task_repo.py
â”‚   â”‚
â”‚   â”œâ”€â”€ tasks/                     # Celery Tasks
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ celery_app.py          # Celery ì•± ì„¤ì •
â”‚   â”‚   â”œâ”€â”€ periodic.py            # ì£¼ê¸°ì  ì‘ì—… (Beat)
â”‚   â”‚   â””â”€â”€ workflows.py           # ì›Œí¬í”Œë¡œìš° ì‘ì—…
â”‚   â”‚
â”‚   â”œâ”€â”€ db/                        # Database
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ session.py             # DB ì„¸ì…˜ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ base.py                # SQLAlchemy Base
â”‚   â”‚   â””â”€â”€ migrations/            # Alembic migrations
â”‚   â”‚       â””â”€â”€ versions/
â”‚   â”‚
â”‚   â”œâ”€â”€ cache/                     # Cache Layer
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ redis_client.py        # Redis í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â””â”€â”€ cache_service.py       # ìºì‹± ë¡œì§
â”‚   â”‚
â”‚   â””â”€â”€ utils/                     # Utilities
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ logger.py              # êµ¬ì¡°í™” ë¡œê¹…
â”‚       â”œâ”€â”€ metrics.py             # Prometheus ë©”íŠ¸ë¦­
â”‚       â””â”€â”€ validators.py          # ê³µí†µ ê²€ì¦ ë¡œì§
â”‚
â”œâ”€â”€ tests/                         # í…ŒìŠ¤íŠ¸
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ conftest.py
â”‚
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml                 # Poetry or setuptools
â””â”€â”€ README.md
```

### 4.2 í•µì‹¬ ì»´í¬ë„ŒíŠ¸ ìƒì„¸ ì„¤ê³„

#### 4.2.1 MCP Server (api/mcp/)

**ì„¤ê³„ ì›ì¹™**:
- Tool ë‹¨ìœ„ ë¶„ë¦¬ (ê° Toolì€ ë…ë¦½ì  ëª¨ë“ˆ)
- Pydantic ê¸°ë°˜ ì…ë ¥ ê²€ì¦
- êµ¬ì¡°í™”ëœ ì—ëŸ¬ ì‘ë‹µ

**êµ¬í˜„ ì˜ˆì‹œ**:
```python
# api/mcp/tools/profile.py
from pydantic import BaseModel, Field
from typing import Optional
from app.services.profile_service import ProfileService

class GetUnifiedProfileInput(BaseModel):
    student_id: str = Field(..., description="í•™ìƒ ID (UUID)")
    include_history: bool = Field(default=True, description="í•™ìŠµ íˆìŠ¤í† ë¦¬ í¬í•¨ ì—¬ë¶€")
    days: int = Field(default=30, description="íˆìŠ¤í† ë¦¬ ì¡°íšŒ ê¸°ê°„ (ì¼)")

class GetUnifiedProfileOutput(BaseModel):
    student_id: str
    basic_info: dict
    knowledge_state: dict
    mastery_levels: dict
    recent_activities: list
    latest_reports: list
    cached: bool
    generated_at: str

async def get_unified_profile(
    input: GetUnifiedProfileInput,
    profile_service: ProfileService
) -> GetUnifiedProfileOutput:
    """
    í†µí•© í”„ë¡œí•„ ì¡°íšŒ
    - Cache-First ì „ëµ
    - Parallel Node í˜¸ì¶œ
    - Graceful Degradation (ì¼ë¶€ ë…¸ë“œ ì‹¤íŒ¨ ì‹œì—ë„ ê°€ëŠ¥í•œ ë°ì´í„° ë°˜í™˜)
    """
    profile = await profile_service.get_unified_profile(
        student_id=input.student_id,
        include_history=input.include_history,
        days=input.days
    )
    return GetUnifiedProfileOutput(**profile)
```

#### 4.2.2 Service Layer (services/)

**ProfileService ì„¤ê³„**:
```python
# services/profile_service.py
import asyncio
from typing import Dict, Optional
from app.cache.cache_service import CacheService
from app.services.mcp_client import MCPClient
from app.repositories.student_repo import StudentRepository

class ProfileService:
    def __init__(
        self,
        student_repo: StudentRepository,
        cache_service: CacheService,
        mcp_client: MCPClient
    ):
        self.student_repo = student_repo
        self.cache = cache_service
        self.mcp = mcp_client

    async def get_unified_profile(
        self,
        student_id: str,
        include_history: bool = True,
        days: int = 30
    ) -> Dict:
        """
        í†µí•© í”„ë¡œí•„ ì¡°íšŒ

        Flow:
        1. Cache í™•ì¸
        2. Cache Miss â†’ DB + Node ë³‘ë ¬ í˜¸ì¶œ
        3. ê²°ê³¼ ë³‘í•© ë° ìºì‹±
        """
        # 1. Cache í™•ì¸
        cache_key = f"profile:{student_id}:{days}"
        cached = await self.cache.get(cache_key)
        if cached:
            cached["cached"] = True
            return cached

        # 2. Master Data ì¡°íšŒ
        student = await self.student_repo.get_by_id(student_id)
        if not student:
            raise ValueError(f"Student {student_id} not found")

        # 3. Node ë³‘ë ¬ í˜¸ì¶œ (Graceful Degradation)
        tasks = {
            "knowledge": self._get_knowledge_state(student_id),
            "mastery": self._get_mastery_levels(student_id),
            "activities": self._get_recent_activities(student_id, days) if include_history else None,
            "reports": self._get_latest_reports(student_id)
        }

        results = {}
        for key, task in tasks.items():
            if task is None:
                results[key] = None
                continue
            try:
                results[key] = await asyncio.wait_for(task, timeout=1.0)
            except asyncio.TimeoutError:
                results[key] = {"error": "timeout"}
            except Exception as e:
                results[key] = {"error": str(e)}

        # 4. ê²°ê³¼ ë³‘í•©
        profile = {
            "student_id": student_id,
            "basic_info": {
                "name": student.name,
                "school_id": student.school_id,
                "grade": student.grade,
                "class_name": student.class_name
            },
            "knowledge_state": results.get("knowledge", {}),
            "mastery_levels": results.get("mastery", {}),
            "recent_activities": results.get("activities", []),
            "latest_reports": results.get("reports", []),
            "cached": False,
            "generated_at": datetime.utcnow().isoformat()
        }

        # 5. Cache ì €ì¥ (TTL: 300s)
        await self.cache.set(cache_key, profile, ttl=300)

        return profile

    async def _get_knowledge_state(self, student_id: str) -> Dict:
        """Node 1: Logic Engine í˜¸ì¶œ"""
        return await self.mcp.call(
            node="logic-engine",
            tool="get_knowledge_state",
            params={"student_id": student_id}
        )

    # ... ë‹¤ë¥¸ Node í˜¸ì¶œ ë©”ì„œë“œ
```

**InterventionService ì„¤ê³„**:
```python
# services/intervention_service.py
from app.tasks.workflows import create_intervention_workflow

class InterventionService:
    async def create_intervention(
        self,
        student_id: str,
        config: InterventionConfig
    ) -> str:
        """
        í•™ìŠµ ê°œì… ìƒì„±

        Flow:
        1. í•™ìƒ ì„±ê³¼ ë¶„ì„ (Node 2)
        2. ì•½ì  ì˜ì—­ ì‹ë³„
        3. í•™ìŠµ ê²½ë¡œ ìƒì„± (Node 3)
        4. DB ì €ì¥
        5. Background Task ìŠ¤ì¼€ì¤„ë§
        """
        # 1. ì„±ê³¼ ë¶„ì„
        weak_areas = await self._analyze_weak_areas(student_id)

        # 2. í•™ìŠµ ê²½ë¡œ ìƒì„±
        learning_path = await self._generate_learning_path(
            student_id=student_id,
            weak_areas=weak_areas,
            target_level=config.target_level
        )

        # 3. Intervention ì €ì¥
        intervention = await self.intervention_repo.create({
            "student_id": student_id,
            "type": config.type,
            "weak_areas": weak_areas,
            "learning_path": learning_path,
            "status": "active",
            "created_at": datetime.utcnow()
        })

        # 4. Background Workflow ì‹œì‘
        create_intervention_workflow.delay(
            intervention_id=intervention.id,
            student_id=student_id
        )

        return intervention.id
```

#### 4.2.3 MCP Client (services/mcp_client.py)

**ì„¤ê³„**:
```python
# services/mcp_client.py
import httpx
from typing import Dict, Any
from app.config import settings

class MCPClient:
    """
    MCP Client for calling Node 1-6

    Features:
    - Connection Pool (ì¬ì‚¬ìš©)
    - Timeout ê´€ë¦¬
    - Retry with Exponential Backoff
    - Circuit Breaker (í–¥í›„)
    """

    NODE_ENDPOINTS = {
        "logic-engine": "http://localhost:8001/mcp",
        "q-dna": "http://localhost:8002/mcp",
        "gen-node": "http://localhost:8003/mcp",
        "lab-node": "http://localhost:8004/mcp",
        "report-node": "http://localhost:8005/mcp",
        "school-info": "http://localhost:8006/mcp"
    }

    def __init__(self):
        self.client = httpx.AsyncClient(
            timeout=httpx.Timeout(30.0),
            limits=httpx.Limits(max_connections=100)
        )

    async def call(
        self,
        node: str,
        tool: str,
        params: Dict[str, Any],
        timeout: float = 30.0
    ) -> Dict:
        """
        MCP Tool í˜¸ì¶œ

        Args:
            node: Node ì´ë¦„ (e.g., "q-dna")
            tool: Tool ì´ë¦„ (e.g., "get_mastery_level")
            params: Tool íŒŒë¼ë¯¸í„°
            timeout: íƒ€ì„ì•„ì›ƒ (ì´ˆ)

        Returns:
            Tool ì‹¤í–‰ ê²°ê³¼

        Raises:
            MCPError: MCP í˜¸ì¶œ ì‹¤íŒ¨
        """
        endpoint = self.NODE_ENDPOINTS.get(node)
        if not endpoint:
            raise ValueError(f"Unknown node: {node}")

        payload = {
            "jsonrpc": "2.0",
            "id": 1,
            "method": "tools/call",
            "params": {
                "name": tool,
                "arguments": params
            }
        }

        try:
            response = await self.client.post(
                endpoint,
                json=payload,
                timeout=timeout
            )
            response.raise_for_status()

            result = response.json()
            if "error" in result:
                raise MCPError(f"{node}.{tool} failed: {result['error']}")

            return result["result"]

        except httpx.TimeoutException:
            raise MCPError(f"{node}.{tool} timeout after {timeout}s")
        except httpx.HTTPError as e:
            raise MCPError(f"{node}.{tool} HTTP error: {e}")
```

#### 4.2.4 Cache Layer (cache/)

**ì„¤ê³„**:
```python
# cache/cache_service.py
import json
from typing import Optional, Any
from redis.asyncio import Redis

class CacheService:
    def __init__(self, redis: Redis):
        self.redis = redis

    async def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        data = await self.redis.get(key)
        if data:
            return json.loads(data)
        return None

    async def set(self, key: str, value: Any, ttl: int = 300):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        await self.redis.setex(
            key,
            ttl,
            json.dumps(value, ensure_ascii=False)
        )

    async def delete(self, key: str):
        """ìºì‹œ ì‚­ì œ"""
        await self.redis.delete(key)

    async def invalidate_pattern(self, pattern: str):
        """íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ìºì‹œ ë¬´íš¨í™”"""
        keys = await self.redis.keys(pattern)
        if keys:
            await self.redis.delete(*keys)
```

#### 4.2.5 Celery Tasks (tasks/)

**ì„¤ê³„**:
```python
# tasks/periodic.py
from celery import Celery
from celery.schedules import crontab

celery_app = Celery("student_hub")

# ì£¼ê¸°ì  ì‘ì—… ìŠ¤ì¼€ì¤„
celery_app.conf.beat_schedule = {
    # ë§¤ì¼ ì˜¤ì „ 9ì‹œ: ì¼ì¼ í•™ìŠµ ë¦¬í¬íŠ¸ ìƒì„±
    "daily-learning-reports": {
        "task": "app.tasks.periodic.generate_daily_reports",
        "schedule": crontab(hour=9, minute=0),
    },
    # ë§¤ì£¼ ì›”ìš”ì¼ ì˜¤ì „ 10ì‹œ: ì£¼ê°„ ë¶„ì„
    "weekly-analytics": {
        "task": "app.tasks.periodic.generate_weekly_analytics",
        "schedule": crontab(day_of_week=1, hour=10, minute=0),
    },
    # ë§¤ì‹œê°„: ê°œì… ì§„í–‰ ìƒíƒœ í™•ì¸
    "check-interventions": {
        "task": "app.tasks.periodic.check_intervention_progress",
        "schedule": crontab(minute=0),  # ë§¤ì‹œ ì •ê°
    }
}

@celery_app.task
def generate_daily_reports():
    """ì¼ì¼ í•™ìŠµ ë¦¬í¬íŠ¸ ìƒì„± (ëª¨ë“  í™œì„± í•™ìƒ)"""
    # êµ¬í˜„ ìƒëµ
    pass

@celery_app.task
def generate_weekly_analytics():
    """ì£¼ê°„ í•™ê¸‰/í•™ë…„ë³„ ë¶„ì„"""
    # êµ¬í˜„ ìƒëµ
    pass
```

---

## 5. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„

### 5.1 ERD (Entity Relationship Diagram)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       students          â”‚ (ë§ˆìŠ¤í„° ë°ì´í„°)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PK  id (UUID)           â”‚
â”‚     name                â”‚
â”‚     school_id           â”‚
â”‚     grade               â”‚
â”‚     class_name          â”‚
â”‚     student_number      â”‚
â”‚     email (nullable)    â”‚
â”‚     parent_contact      â”‚
â”‚     metadata (JSONB)    â”‚
â”‚     created_at          â”‚
â”‚     updated_at          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ 1
         â”‚
         â”‚ N
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  learning_history       â”‚ (í•™ìŠµ ì´ë²¤íŠ¸ - ì‹œê³„ì—´)
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PK  id (BIGSERIAL)      â”‚
â”‚ FK  student_id (UUID)   â”‚
â”‚     event_type          â”‚ (study, test, intervention)
â”‚     source_node         â”‚ (1-6)
â”‚     source_id           â”‚ (ì›ë³¸ ë°ì´í„° ID)
â”‚     content (JSONB)     â”‚ (ì´ë²¤íŠ¸ ìƒì„¸)
â”‚     occurred_at         â”‚ (íŒŒí‹°ì…˜ í‚¤)
â”‚     created_at          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â”‚
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         â”‚
â”‚                         â”‚
â†“                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ interventions    â”‚   â”‚  scheduled_tasks     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ PK id (UUID)     â”‚   â”‚ PK id (UUID)         â”‚
â”‚ FK student_id    â”‚   â”‚ FK student_id        â”‚
â”‚    type          â”‚   â”‚    task_type         â”‚
â”‚    weak_areas    â”‚   â”‚    schedule_type     â”‚
â”‚    learning_path â”‚   â”‚    cron_expression   â”‚
â”‚    status        â”‚   â”‚    config (JSONB)    â”‚
â”‚    progress      â”‚   â”‚    next_run_at       â”‚
â”‚    created_at    â”‚   â”‚    last_run_at       â”‚
â”‚    completed_at  â”‚   â”‚    status            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚    celery_task_id    â”‚
                       â”‚    created_at        â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 5.2 í…Œì´ë¸” ìƒì„¸ ìŠ¤í‚¤ë§ˆ

#### 5.2.1 students (í•™ìƒ ë§ˆìŠ¤í„° ë°ì´í„°)
```sql
CREATE TABLE students (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(100) NOT NULL,
    school_id VARCHAR(50) NOT NULL,
    grade INTEGER NOT NULL CHECK (grade >= 1 AND grade <= 12),
    class_name VARCHAR(50),
    student_number VARCHAR(20),
    email VARCHAR(255),
    parent_contact VARCHAR(20),
    metadata JSONB DEFAULT '{}',  -- í™•ì¥ ê°€ëŠ¥í•œ ë©”íƒ€ë°ì´í„°
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),

    -- ì¸ë±ìŠ¤
    CONSTRAINT students_school_grade_class_number_unique
        UNIQUE (school_id, grade, class_name, student_number)
);

CREATE INDEX idx_students_school_id ON students(school_id);
CREATE INDEX idx_students_grade_class ON students(grade, class_name);
CREATE INDEX idx_students_metadata ON students USING GIN (metadata);
```

**metadata ì˜ˆì‹œ**:
```json
{
  "learning_style": "visual",
  "special_needs": false,
  "interests": ["math", "science"],
  "parent_preferences": {
    "notification_method": "email",
    "report_frequency": "weekly"
  }
}
```

#### 5.2.2 learning_history (í•™ìŠµ ì´ë²¤íŠ¸ - ì‹œê³„ì—´ ë°ì´í„°)
```sql
CREATE TABLE learning_history (
    id BIGSERIAL,
    student_id UUID NOT NULL REFERENCES students(id) ON DELETE CASCADE,
    event_type VARCHAR(50) NOT NULL,  -- 'study', 'test', 'intervention'
    source_node INTEGER NOT NULL CHECK (source_node >= 1 AND source_node <= 6),
    source_id VARCHAR(255),  -- ì›ë³¸ ë…¸ë“œì˜ ë°ì´í„° ID
    content JSONB NOT NULL,
    occurred_at TIMESTAMP NOT NULL,  -- íŒŒí‹°ì…˜ í‚¤
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),

    PRIMARY KEY (id, occurred_at)
) PARTITION BY RANGE (occurred_at);

-- ì›”ë³„ íŒŒí‹°ì…˜ (ì˜ˆì‹œ: 2026ë…„ 1ì›”)
CREATE TABLE learning_history_2026_01 PARTITION OF learning_history
    FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

-- ì¸ë±ìŠ¤
CREATE INDEX idx_lh_student_occurred ON learning_history(student_id, occurred_at DESC);
CREATE INDEX idx_lh_event_type ON learning_history(event_type);
CREATE INDEX idx_lh_content ON learning_history USING GIN (content);
```

**content ì˜ˆì‹œ**:
```json
{
  "node": 2,
  "action": "solved_problem",
  "problem_id": "prob_12345",
  "result": "correct",
  "time_spent": 180,
  "difficulty": 0.65
}
```

#### 5.2.3 interventions (í•™ìŠµ ê°œì…)
```sql
CREATE TABLE interventions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    student_id UUID NOT NULL REFERENCES students(id) ON DELETE CASCADE,
    type VARCHAR(50) NOT NULL,  -- 'auto', 'teacher_requested'
    weak_areas JSONB NOT NULL,  -- ì•½ì  ì˜ì—­ ë¶„ì„ ê²°ê³¼
    learning_path JSONB NOT NULL,  -- ìƒì„±ëœ í•™ìŠµ ê²½ë¡œ
    status VARCHAR(20) NOT NULL DEFAULT 'active',  -- 'active', 'paused', 'completed', 'cancelled'
    progress JSONB DEFAULT '{"completed": 0, "total": 0}',
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    completed_at TIMESTAMP,

    CHECK (status IN ('active', 'paused', 'completed', 'cancelled'))
);

CREATE INDEX idx_interventions_student ON interventions(student_id);
CREATE INDEX idx_interventions_status ON interventions(status);
CREATE INDEX idx_interventions_created ON interventions(created_at DESC);
```

#### 5.2.4 scheduled_tasks (ì£¼ê¸°ì  ì‘ì—…)
```sql
CREATE TABLE scheduled_tasks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    student_id UUID REFERENCES students(id) ON DELETE CASCADE,  -- NULL for global tasks
    task_type VARCHAR(50) NOT NULL,  -- 'daily_report', 'weekly_analytics', etc.
    schedule_type VARCHAR(20) NOT NULL,  -- 'cron', 'interval', 'one_time'
    cron_expression VARCHAR(100),  -- cron í‘œí˜„ì‹ (schedule_type='cron')
    config JSONB NOT NULL DEFAULT '{}',
    next_run_at TIMESTAMP,
    last_run_at TIMESTAMP,
    status VARCHAR(20) NOT NULL DEFAULT 'active',
    celery_task_id VARCHAR(255),  -- Celery Task ID
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),

    CHECK (schedule_type IN ('cron', 'interval', 'one_time')),
    CHECK (status IN ('active', 'paused', 'completed'))
);

CREATE INDEX idx_tasks_next_run ON scheduled_tasks(next_run_at) WHERE status = 'active';
CREATE INDEX idx_tasks_student ON scheduled_tasks(student_id);
```

### 5.3 Database Migration Strategy

**Tool**: Alembic

**ì˜ˆì‹œ Migration**:
```python
# migrations/versions/001_initial_schema.py
def upgrade():
    op.create_table(
        'students',
        sa.Column('id', postgresql.UUID(), nullable=False),
        sa.Column('name', sa.String(100), nullable=False),
        # ... ìƒëµ
        sa.PrimaryKeyConstraint('id')
    )

def downgrade():
    op.drop_table('students')
```

---

## 6. MCP í†µì‹  ì„¤ê³„

### 6.1 MCP Server Tools ìƒì„¸ ëª…ì„¸

#### Tool 1: get_unified_profile

**Request**:
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "method": "tools/call",
  "params": {
    "name": "get_unified_profile",
    "arguments": {
      "student_id": "550e8400-e29b-41d4-a716-446655440000",
      "include_history": true,
      "days": 30
    }
  }
}
```

**Response**:
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "result": {
    "student_id": "550e8400-e29b-41d4-a716-446655440000",
    "basic_info": {
      "name": "ê¹€ì² ìˆ˜",
      "school_id": "SCH001",
      "grade": 10,
      "class_name": "1ë°˜"
    },
    "knowledge_state": {
      "node": 1,
      "concepts": [
        {"name": "ì´ì°¨ë°©ì •ì‹", "mastery": 0.85},
        {"name": "í•¨ìˆ˜", "mastery": 0.72}
      ]
    },
    "mastery_levels": {
      "node": 2,
      "overall": 0.78,
      "by_subject": {
        "math": 0.82,
        "science": 0.74
      }
    },
    "recent_activities": [
      {
        "date": "2026-01-08",
        "type": "study",
        "duration": 3600,
        "problems_solved": 15
      }
    ],
    "latest_reports": [
      {
        "report_id": "REP123",
        "type": "weekly",
        "generated_at": "2026-01-05T10:00:00Z"
      }
    ],
    "cached": false,
    "generated_at": "2026-01-09T05:30:00Z"
  }
}
```

#### Tool 2: create_learning_intervention

**Request**:
```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "method": "tools/call",
  "params": {
    "name": "create_learning_intervention",
    "arguments": {
      "student_id": "550e8400-e29b-41d4-a716-446655440000",
      "type": "auto",
      "target_level": 0.85,
      "duration_days": 14
    }
  }
}
```

**Response**:
```json
{
  "jsonrpc": "2.0",
  "id": 2,
  "result": {
    "intervention_id": "INT_abc123",
    "student_id": "550e8400-e29b-41d4-a716-446655440000",
    "weak_areas": [
      {
        "concept": "ì´ì°¨í•¨ìˆ˜",
        "current_mastery": 0.65,
        "target_mastery": 0.85
      }
    ],
    "learning_path": [
      {
        "step": 1,
        "activity": "review_concept",
        "concept": "ì´ì°¨í•¨ìˆ˜ ê¸°ë³¸",
        "estimated_duration": 1800
      },
      {
        "step": 2,
        "activity": "practice",
        "problem_set_id": "PS_456",
        "num_problems": 10
      }
    ],
    "scheduled_tasks": [
      {
        "task_id": "TASK_789",
        "type": "progress_check",
        "scheduled_at": "2026-01-16T10:00:00Z"
      }
    ],
    "status": "active",
    "created_at": "2026-01-09T05:30:00Z"
  }
}
```

### 6.2 MCP Client í˜¸ì¶œ íŒ¨í„´

#### 6.2.1 ë³‘ë ¬ í˜¸ì¶œ (Fan-Out Pattern)
```python
async def get_unified_profile(student_id: str):
    # ì—¬ëŸ¬ ë…¸ë“œì— ë™ì‹œ ìš”ì²­
    tasks = [
        mcp_client.call("logic-engine", "get_knowledge_state", {"student_id": student_id}),
        mcp_client.call("q-dna", "get_mastery_level", {"student_id": student_id}),
        mcp_client.call("lab-node", "get_recent_activities", {"student_id": student_id, "days": 30}),
        mcp_client.call("report-node", "get_latest_reports", {"student_id": student_id})
    ]

    # ëª¨ë‘ ì™„ë£Œ ëŒ€ê¸° (ìµœëŒ€ 2ì´ˆ)
    results = await asyncio.gather(*tasks, return_exceptions=True)

    # ì‹¤íŒ¨í•œ í˜¸ì¶œ ì²˜ë¦¬ (Graceful Degradation)
    return merge_results(results)
```

#### 6.2.2 ìˆœì°¨ í˜¸ì¶œ (Sequential Pattern)
```python
async def create_intervention(student_id: str):
    # 1. ì•½ì  ë¶„ì„ (Node 2)
    weak_areas = await mcp_client.call(
        "q-dna",
        "analyze_weak_areas",
        {"student_id": student_id}
    )

    # 2. í•™ìŠµ ê²½ë¡œ ìƒì„± (Node 3) - ì•½ì  ë¶„ì„ ê²°ê³¼ í•„ìš”
    learning_path = await mcp_client.call(
        "gen-node",
        "generate_learning_path",
        {
            "student_id": student_id,
            "weak_areas": weak_areas
        }
    )

    return learning_path
```

### 6.3 Error Handling & Retry

**Retry ì „ëµ**:
```python
from tenacity import retry, stop_after_attempt, wait_exponential

@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=1, max=10)
)
async def call_with_retry(node: str, tool: str, params: dict):
    return await mcp_client.call(node, tool, params)
```

**ì—ëŸ¬ ì‘ë‹µ**:
```json
{
  "jsonrpc": "2.0",
  "id": 1,
  "error": {
    "code": -32001,
    "message": "Node communication failed",
    "data": {
      "node": "q-dna",
      "tool": "get_mastery_level",
      "reason": "timeout after 30s"
    }
  }
}
```

---

## 7. ì›Œí¬í”Œë¡œìš° ì—”ì§„

### 7.1 Celery ì›Œí¬í”Œë¡œìš° ì„¤ê³„

#### 7.1.1 ê°œì… ìƒì„± ì›Œí¬í”Œë¡œìš°
```python
# tasks/workflows.py
from celery import chain, group

@celery_app.task
def create_intervention_workflow(intervention_id: str, student_id: str):
    """
    ê°œì… ìƒì„± í›„ ì‹¤í–‰ë˜ëŠ” ì›Œí¬í”Œë¡œìš°

    1. ì•Œë¦¼ ì „ì†¡ (í•™ìƒ, í•™ë¶€ëª¨, êµì‚¬)
    2. ë¶„ì„ ë°ì´í„° ì—…ë°ì´íŠ¸
    3. 7ì¼ í›„ ì§„í–‰ ìƒíƒœ í™•ì¸ ìŠ¤ì¼€ì¤„ë§
    """
    workflow = chain(
        send_notifications.s(intervention_id, student_id),
        update_analytics.s(student_id),
        schedule_progress_check.s(intervention_id, days=7)
    )

    return workflow.apply_async()

@celery_app.task
def send_notifications(intervention_id: str, student_id: str):
    """ì•Œë¦¼ ì „ì†¡ (í•™ìƒ, í•™ë¶€ëª¨, êµì‚¬)"""
    # êµ¬í˜„ ìƒëµ
    pass

@celery_app.task
def update_analytics(student_id: str):
    """ë¶„ì„ ë°ì´í„° ì—…ë°ì´íŠ¸"""
    # êµ¬í˜„ ìƒëµ
    pass

@celery_app.task
def schedule_progress_check(intervention_id: str, days: int):
    """ì§„í–‰ ìƒíƒœ í™•ì¸ ìŠ¤ì¼€ì¤„ë§"""
    # êµ¬í˜„ ìƒëµ
    pass
```

#### 7.1.2 ì£¼ê¸°ì  ë¦¬í¬íŠ¸ ìƒì„±
```python
@celery_app.task
def generate_daily_reports():
    """
    ì¼ì¼ í•™ìŠµ ë¦¬í¬íŠ¸ ìƒì„±

    1. í™œì„± í•™ìƒ ì¡°íšŒ
    2. ë³‘ë ¬ë¡œ ë¦¬í¬íŠ¸ ìƒì„± (ê·¸ë£¹ íƒœìŠ¤í¬)
    3. ê²°ê³¼ ì§‘ê³„ ë° ì €ì¥
    """
    active_students = get_active_students()

    # ë³‘ë ¬ ì²˜ë¦¬
    job = group([
        generate_student_report.s(student_id)
        for student_id in active_students
    ])

    result = job.apply_async()
    return result.get()

@celery_app.task
def generate_student_report(student_id: str):
    """ê°œë³„ í•™ìƒ ë¦¬í¬íŠ¸ ìƒì„±"""
    # Node 5 (Report Node) í˜¸ì¶œ
    report = await mcp_client.call(
        "report-node",
        "generate_daily_report",
        {"student_id": student_id}
    )
    return report
```

### 7.2 Task Priority

**Queue êµ¬ì¡°**:
```python
# config.py
CELERY_TASK_ROUTES = {
    'app.tasks.workflows.create_intervention_workflow': {
        'queue': 'high_priority'
    },
    'app.tasks.periodic.generate_daily_reports': {
        'queue': 'low_priority'
    },
    'app.tasks.workflows.send_notifications': {
        'queue': 'default'
    }
}
```

**Worker êµ¬ì„±**:
```bash
# High-priority worker
celery -A app.tasks.celery_app worker -Q high_priority -c 4

# Default worker
celery -A app.tasks.celery_app worker -Q default -c 8

# Low-priority worker (batch jobs)
celery -A app.tasks.celery_app worker -Q low_priority -c 2
```

---

## 8. ì„±ëŠ¥ ìµœì í™”

### 8.1 Caching Strategy

#### 8.1.1 Cache Layers

| Layer | TTL | ìš©ë„ | Key íŒ¨í„´ |
|-------|-----|------|----------|
| **L1: Profile Cache** | 300s (5ë¶„) | í†µí•© í”„ë¡œí•„ | `profile:{student_id}:{days}` |
| **L2: Node Response Cache** | 60s (1ë¶„) | ê°œë³„ ë…¸ë“œ ì‘ë‹µ | `node:{node_id}:{tool}:{hash}` |
| **L3: Analytics Cache** | 3600s (1ì‹œê°„) | í•™ê¸‰/í•™ë…„ ë¶„ì„ | `analytics:{class_id}:{date}` |

#### 8.1.2 Cache Invalidation

**ì „ëµ**:
- **Time-based**: TTL ê¸°ë°˜ ìë™ ë§Œë£Œ
- **Event-based**: í•™ìƒ ë°ì´í„° ë³€ê²½ ì‹œ íŒ¨í„´ ë§¤ì¹­ ë¬´íš¨í™”

**êµ¬í˜„**:
```python
async def invalidate_student_cache(student_id: str):
    """í•™ìƒ ê´€ë ¨ ìºì‹œ ë¬´íš¨í™”"""
    patterns = [
        f"profile:{student_id}:*",
        f"node:*:*:*{student_id}*",
        f"analytics:*"  # í•™ê¸‰ ë¶„ì„ë„ ë¬´íš¨í™”
    ]

    for pattern in patterns:
        await cache_service.invalidate_pattern(pattern)
```

### 8.2 Database Optimization

#### 8.2.1 Index Strategy
```sql
-- ìì£¼ ì¡°íšŒë˜ëŠ” ì»¬ëŸ¼
CREATE INDEX idx_students_school_id ON students(school_id);
CREATE INDEX idx_students_grade_class ON students(grade, class_name);

-- ì‹œê³„ì—´ ì¿¼ë¦¬
CREATE INDEX idx_lh_student_occurred ON learning_history(student_id, occurred_at DESC);

-- JSONB í•„ë“œ
CREATE INDEX idx_students_metadata ON students USING GIN (metadata);
CREATE INDEX idx_lh_content ON learning_history USING GIN (content);
```

#### 8.2.2 Partitioning
```sql
-- learning_history: ì›”ë³„ íŒŒí‹°ì…˜
CREATE TABLE learning_history_2026_01 PARTITION OF learning_history
    FOR VALUES FROM ('2026-01-01') TO ('2026-02-01');

-- ìë™ íŒŒí‹°ì…˜ ìƒì„± (pg_partman ì‚¬ìš©)
```

#### 8.2.3 Connection Pooling
```python
# db/session.py
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession

engine = create_async_engine(
    DATABASE_URL,
    echo=False,
    pool_size=20,           # ê¸°ë³¸ í’€ í¬ê¸°
    max_overflow=10,        # ìµœëŒ€ ì¶”ê°€ ì—°ê²°
    pool_pre_ping=True,     # ì—°ê²° ìœ íš¨ì„± ê²€ì‚¬
    pool_recycle=3600       # 1ì‹œê°„ë§ˆë‹¤ ì—°ê²° ì¬ìƒì„±
)
```

### 8.3 MCP Call Optimization

#### 8.3.1 Parallel Calls with Timeout
```python
async def parallel_mcp_calls(calls: List[Dict]):
    """ë³‘ë ¬ MCP í˜¸ì¶œ with ê°œë³„ Timeout"""
    tasks = []
    for call in calls:
        task = asyncio.create_task(
            mcp_client.call(
                call["node"],
                call["tool"],
                call["params"],
                timeout=call.get("timeout", 30.0)
            )
        )
        tasks.append(task)

    # Graceful Degradation
    results = []
    for task in asyncio.as_completed(tasks):
        try:
            result = await task
            results.append(result)
        except Exception as e:
            results.append({"error": str(e)})

    return results
```

#### 8.3.2 Request Batching (í–¥í›„)
```python
async def batch_get_profiles(student_ids: List[str]):
    """ì—¬ëŸ¬ í”„ë¡œí•„ ë°°ì¹˜ ì¡°íšŒ (1ê°œ ìš”ì²­ìœ¼ë¡œ ìµœì í™”)"""
    # êµ¬í˜„ ì˜ˆì •
    pass
```

---

## 9. ë³´ì•ˆ ì„¤ê³„

### 9.1 ì¸ì¦ & ì¸ê°€

**Phase 1 (í˜„ì¬)**: API Key ê¸°ë°˜
```python
# api/deps.py
from fastapi import Security, HTTPException
from fastapi.security import APIKeyHeader

api_key_header = APIKeyHeader(name="X-API-Key")

async def verify_api_key(api_key: str = Security(api_key_header)):
    if api_key not in settings.ALLOWED_API_KEYS:
        raise HTTPException(status_code=403, detail="Invalid API key")
    return api_key
```

**Phase 2 (ê³„íš)**: OAuth 2.0 + JWT
- Keycloak í†µí•©
- Role-based Access Control (RBAC)

### 9.2 ë°ì´í„° ë³´ì•ˆ

#### 9.2.1 ê°œì¸ì •ë³´ ì•”í˜¸í™”
```python
# utils/crypto.py
from cryptography.fernet import Fernet

class EncryptionService:
    def __init__(self, key: bytes):
        self.cipher = Fernet(key)

    def encrypt(self, data: str) -> str:
        """ë¯¼ê° ì •ë³´ ì•”í˜¸í™” (ì´ë¦„, ì—°ë½ì²˜ ë“±)"""
        return self.cipher.encrypt(data.encode()).decode()

    def decrypt(self, encrypted: str) -> str:
        return self.cipher.decrypt(encrypted.encode()).decode()
```

**ì ìš© í•„ë“œ**:
- `students.name`: ì•”í˜¸í™” ì €ì¥
- `students.parent_contact`: ì•”í˜¸í™” ì €ì¥
- `students.email`: ì•”í˜¸í™” ì €ì¥

#### 9.2.2 ì ‘ê·¼ ì œì–´
```python
# services/profile_service.py
async def get_unified_profile(self, student_id: str, requester_id: str):
    # ê¶Œí•œ í™•ì¸
    if not await self.can_access(requester_id, student_id):
        raise PermissionError("Access denied")

    # ... í”„ë¡œí•„ ì¡°íšŒ
```

### 9.3 Rate Limiting

```python
# middleware/rate_limit.py
from slowapi import Limiter
from slowapi.util import get_remote_address

limiter = Limiter(key_func=get_remote_address)

@app.get("/mcp/tools/get_unified_profile")
@limiter.limit("100/minute")
async def get_profile(...):
    pass
```

---

## 10. ëª¨ë‹ˆí„°ë§ ë° ë¡œê¹…

### 10.1 Structured Logging

```python
# utils/logger.py
import structlog

logger = structlog.get_logger()

# ì‚¬ìš© ì˜ˆì‹œ
logger.info(
    "profile_fetched",
    student_id=student_id,
    cached=cached,
    duration_ms=duration,
    nodes_called=["q-dna", "logic-engine"]
)
```

**Log í˜•ì‹** (JSON):
```json
{
  "event": "profile_fetched",
  "student_id": "550e8400-e29b-41d4-a716-446655440000",
  "cached": false,
  "duration_ms": 1823,
  "nodes_called": ["q-dna", "logic-engine"],
  "timestamp": "2026-01-09T05:30:15Z",
  "level": "info"
}
```

### 10.2 Metrics (Prometheus)

```python
# utils/metrics.py
from prometheus_client import Counter, Histogram, Gauge

# Counters
mcp_calls_total = Counter(
    "mcp_calls_total",
    "Total MCP calls",
    ["node", "tool", "status"]
)

# Histograms
profile_fetch_duration = Histogram(
    "profile_fetch_duration_seconds",
    "Profile fetch duration",
    buckets=[0.1, 0.5, 1.0, 2.0, 5.0]
)

# Gauges
active_interventions = Gauge(
    "active_interventions",
    "Number of active interventions"
)
```

**ì‚¬ìš©**:
```python
with profile_fetch_duration.time():
    profile = await get_unified_profile(student_id)

mcp_calls_total.labels(node="q-dna", tool="get_mastery", status="success").inc()
```

### 10.3 Health Check

```python
# api/rest/health.py
from fastapi import APIRouter

router = APIRouter()

@router.get("/health")
async def health_check():
    """
    í—¬ìŠ¤ ì²´í¬
    - Database ì—°ê²°
    - Redis ì—°ê²°
    - MCP Client ìƒíƒœ
    """
    checks = {
        "database": await check_db(),
        "redis": await check_redis(),
        "mcp_clients": await check_mcp_clients()
    }

    healthy = all(checks.values())

    return {
        "status": "healthy" if healthy else "unhealthy",
        "checks": checks,
        "timestamp": datetime.utcnow().isoformat()
    }
```

### 10.4 Distributed Tracing (í–¥í›„)

**OpenTelemetry í†µí•©**:
```python
# ê³„íš
from opentelemetry import trace

tracer = trace.get_tracer(__name__)

@tracer.start_as_current_span("get_unified_profile")
async def get_unified_profile(student_id: str):
    span = trace.get_current_span()
    span.set_attribute("student_id", student_id)
    # ...
```

---

## ë¶€ë¡

### A. ê¸°ìˆ  ìŠ¤íƒ ë²„ì „ ëª…ì„¸

| Component | Version | ë¹„ê³  |
|-----------|---------|------|
| Python | 3.11+ | Type Hints, Performance |
| FastAPI | 0.104+ | Async, Pydantic v2 |
| PostgreSQL | 14+ | Partitioning, JSONB |
| Redis | 7+ | Async client |
| Celery | 5.3+ | Task queue |
| SQLAlchemy | 2.0+ | Async ORM |
| Pydantic | 2.0+ | ì„±ëŠ¥ ê°œì„  |
| httpx | 0.24+ | Async HTTP client |
| structlog | 23.0+ | êµ¬ì¡°í™” ë¡œê¹… |
| prometheus-client | 0.18+ | Metrics |

### B. í™˜ê²½ ë³€ìˆ˜

```bash
# Database
DATABASE_URL=postgresql+asyncpg://user:pass@localhost:5432/mathesis_hub

# Redis
REDIS_URL=redis://localhost:6379/0

# Celery
CELERY_BROKER_URL=redis://localhost:6379/1
CELERY_RESULT_BACKEND=redis://localhost:6379/2

# Security
API_KEY=your-secret-api-key
ENCRYPTION_KEY=your-encryption-key

# MCP Nodes
NODE1_URL=http://localhost:8001/mcp
NODE2_URL=http://localhost:8002/mcp
# ... Node 3-6

# Logging
LOG_LEVEL=INFO
LOG_FORMAT=json
```

### C. Performance Benchmarks (ëª©í‘œ)

| Metric | Target | ì¸¡ì • ë°©ë²• |
|--------|--------|-----------|
| Profile fetch (cached) | < 100ms | p95 |
| Profile fetch (uncached) | < 2000ms | p95 |
| Intervention creation | < 3000ms | p95 |
| MCP call (single) | < 500ms | p95 |
| DB query (indexed) | < 50ms | p95 |
| Cache hit rate | > 80% | Profile fetches |

---

**Document Version**: 1.0.0
**Last Updated**: 2026-01-09
**Review Date**: 2026-02-09
**Approved By**: [Pending]
